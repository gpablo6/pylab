{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a corpus available for local usage with the library. If you try using a corpora that is not available it will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to ../nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cess_esp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that this corpus is in spanish.\n",
    "# The content are news headlines in spanish from multiple sources.\n",
    "nltk.download(\n",
    "    'cess_esp',\n",
    "    download_dir='../nltk_data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Running this cell will download the corpus to the local machine.\n",
    "You can go to your home directory and find the `nltk_data` folder if no `download_dir` is specified.\n",
    "\n",
    "If you delete the folder where the corpus is hosted, you will have to run this cell again to download the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if using a custom download_dir\n",
    "import pathlib\n",
    "\n",
    "# Add the path to the nltk_data directory\n",
    "abs_path = pathlib.Path('../nltk_data').resolve()\n",
    "nltk.data.path.append(str(abs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the corpus available for usage\n",
    "corpus = nltk.corpus.cess_esp.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample corpus content: [['El', 'grupo', 'estatal', 'Electricité_de_France', '-Fpa-', 'EDF', '-Fpt-', 'anunció', 'hoy', ',', 'jueves', ',', 'la', 'compra', 'del', '51_por_ciento', 'de', 'la', 'empresa', 'mexicana', 'Electricidad_Águila_de_Altamira', '-Fpa-', 'EAA', '-Fpt-', ',', 'creada', 'por', 'el', 'japonés', 'Mitsubishi_Corporation', 'para', 'poner_en_marcha', 'una', 'central', 'de', 'gas', 'de', '495', 'megavatios', '.'], ['Una', 'portavoz', 'de', 'EDF', 'explicó', 'a', 'EFE', 'que', 'el', 'proyecto', 'para', 'la', 'construcción', 'de', 'Altamira_2', ',', 'al', 'norte', 'de', 'Tampico', ',', 'prevé', 'la', 'utilización', 'de', 'gas', 'natural', 'como', 'combustible', 'principal', 'en', 'una', 'central', 'de', 'ciclo', 'combinado', 'que', 'debe', 'empezar', 'a', 'funcionar', 'en', 'mayo_del_2002', '.'], ...]\n",
      "Number of sentences in corpus: 6030\n"
     ]
    }
   ],
   "source": [
    "# Check corpus content (it's already tokenized)\n",
    "print(f\"Sample corpus content: {corpus}\")\n",
    "print(f\"Number of sentences in corpus: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to unpack the content of the corpus for easier usage, thus we flatten the nested structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_corpus = [word for sentence in corpus for word in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in corpus: 192686\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total words in corpus: {len(flattened_corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage regex for text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter words that start with 'es'\n",
    "# https://docs.python.org/3/library/re.html#search-vs-match\n",
    "filtered_corpus = [\n",
    "    word\n",
    "    for word in flattened_corpus\n",
    "    if re.search(\n",
    "        r'es',\n",
    "        word\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estatal', 'jueves', 'empresa', 'centrales', 'francesa']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get words that end with 'es'\n",
    "filtered_corpus_end_word = [\n",
    "    word\n",
    "    for word in flattened_corpus\n",
    "    if re.search(\n",
    "        r'es$',\n",
    "        word\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jueves', 'centrales', 'millones', 'millones', 'dólares']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_corpus_end_word[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words that start with 'es'\n",
    "filtered_corpus_start_word = [\n",
    "    word\n",
    "    for word in flattened_corpus\n",
    "    if re.search(\n",
    "        r'^es',\n",
    "        word\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estatal', 'es', 'esta', 'esta', 'eso']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_corpus_start_word[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex filtering, we can use regex ranges, such as `a-z` for all lowercase letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words that begin with 'g', 'h' or 'i'\n",
    "filtered_corpus_range_example = [\n",
    "    word\n",
    "    for word in flattened_corpus\n",
    "    if re.search(\n",
    "        r'^[ghi]',\n",
    "        word\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grupo', 'hoy', 'gas', 'gas', 'intervendrá']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_corpus_range_example[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By combining quantifiers (indicate numbers of characters or expressions to match, eg. `*` or `+`) with ranges, we can improve our filtering.\n",
    "\n",
    "https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words that begin with at least 'no' zero or more times\n",
    "filtered_corpus_quantifiers_example = [\n",
    "    word\n",
    "    for word in flattened_corpus\n",
    "    if re.search(\n",
    "        r'^(no)+',\n",
    "        word\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['norte', 'no', 'no', 'noche', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_corpus_quantifiers_example[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundations-nlp-nltk-2fxEdyPy-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
